[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The 2026 ACIC Data Challenge",
    "section": "",
    "text": "After a multi-year hiatus, we are excited to announce the return of the ACIC Data Challenge. This year the challenge will focus on the complications that arise in situations with multiple treatments. This will help us to understand how causal inference approaches handle the competing demands of settings with a wide variety of estimands. What’s the best approach to avoiding overconfidence in situations involving multiple, dependent comparisons? Can the same method yield strong results for both ATEs and subgroup effects? What are the tradeoffs between accurately estimating the effects of different treatments versus determining which of those treatments is most efficacious? Do effect rankings suggest a different approach than accurate effect estimates? We hope to address questions like these and more!\nIn addition, a key goal this year is to create a more inclusive competition by lowering the barriers to entry with regard to computing power and level of automation. To that end our datasets will be reasonably small (likely no more than 5000 observations). Moreover, for those who prefer more curated approaches to causal inference we will provide opportunities to make submissions only for a core subset of datasets or estimands.\nWe will release the data on February 1, 2026. Submissions will be due on April 20, 2026. We will announce the results at ACIC in May!"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "The 2026 ACIC Data Challenge",
    "section": "",
    "text": "After a multi-year hiatus, we are excited to announce the return of the ACIC Data Challenge. This year the challenge will focus on the complications that arise in situations with multiple treatments. This will help us to understand how causal inference approaches handle the competing demands of settings with a wide variety of estimands. What’s the best approach to avoiding overconfidence in situations involving multiple, dependent comparisons? Can the same method yield strong results for both ATEs and subgroup effects? What are the tradeoffs between accurately estimating the effects of different treatments versus determining which of those treatments is most efficacious? Do effect rankings suggest a different approach than accurate effect estimates? We hope to address questions like these and more!\nIn addition, a key goal this year is to create a more inclusive competition by lowering the barriers to entry with regard to computing power and level of automation. To that end our datasets will be reasonably small (likely no more than 5000 observations). Moreover, for those who prefer more curated approaches to causal inference we will provide opportunities to make submissions only for a core subset of datasets or estimands.\nWe will release the data on February 1, 2026. Submissions will be due on April 20, 2026. We will announce the results at ACIC in May!"
  }
]